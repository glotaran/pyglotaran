name: "PR Benchmarks"

on:
  pull_request:

jobs:
  run_benchmark:
    name: "Run AVS"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha }}
      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
      - name: Install ASV
        run: |
          pip install 'asv!=0.5' virtualenv packaging

      - name: show home file
        run: |
          ls -lah ~
          realpath ~
      - name: Create machine-file
        shell: python
        run: |
          from pathlib import Path
          machine_file = Path("/home/runner/.asv-machine.json")
          machine_file_content = '''
          {
            "gh_action": {
              "arch": "x86_64",
              "cpu": "Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz",
              "num_cpu": "2",
              "machine": "gh_action",
              "os": "Linux 5.8.0-1033-azure",
              "ram": "7GB"
            },
            "version": 1
          }'''
          machine_file.write_text(machine_file_content)

      - name: Run PR compare benchmarks
        id: benchmark_run
        run: |
          git remote add upstream https://github.com/glotaran/pyglotaran
          git fetch upstream
          pushd benchmark
          last_tag=$(git describe --tags $(git rev-list --tags --max-count=1))
          asv run $last_tag^..$last_tag --machine gh_action
          asv run upstream/main^..upstream/main --machine gh_action
          asv run HEAD^..HEAD --machine gh_action
          asv publish
          echo "last_tag=$last_tag" >> $GITHUB_OUTPUT

      - name: Checkout benchmark result repo
        uses: actions/checkout@v4
        with:
          repository: "glotaran/pyglotaran-benchmarks"
          ref: main
          path: benchmark-repo
      - name: Copy benchmark workflows to html folder
        run: |
          cp -r benchmark-repo/.github benchmark/.asv/html
          ls -lah benchmark/.asv/html

      - name: Create PR comment body
        shell: python
        env:
          PR_NR: ${{github.event.number}}
        run: |
          import os
          from pathlib import Path
          import subprocess

          pr_nr = os.environ.get("PR_NR")
          diff_release_main = subprocess.run(
              ["asv", "--config=benchmark/asv.conf.json", "compare", "${{steps.benchmark_run.outputs.last_tag}}", "upstream/main"],
              capture_output=True,
          )
          diff_main_PR = subprocess.run(
              ["asv", "--config=benchmark/asv.conf.json", "compare", "upstream/main", "HEAD"],
              capture_output=True,
          )
          comment = f"""\
          Benchmark is done. Checkout the [benchmark result page](https://glotaran.github.io/pyglotaran-benchmarks/prs/pr-{pr_nr}).
          Benchmark differences below 5% might be due to CI noise.
          <details>
          <summary>
          Benchmark diff ${{steps.benchmark_run.outputs.last_tag}} vs. main
          </summary>

          ```
          {diff_release_main.stdout.decode()}
          ```
          </details>

          <details>
          <summary>
          Benchmark diff main vs. PR
          </summary>

          ```
          {diff_main_PR.stdout.decode()}
          ```
          </details>
          """

          Path("benchmark/.asv/html/pr-diff-comment.txt").write_text(comment)
          Path("benchmark/.asv/html/origin_pr_nr.txt").write_text(pr_nr)

      - name: Upload PR html results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-pr-html
          path: benchmark/.asv/html
